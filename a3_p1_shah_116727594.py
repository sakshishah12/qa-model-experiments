# -*- coding: utf-8 -*-
"""a3_p1_Shah_116727594.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lYQrDnqf8Utee2fL6DZpDf5VDQL03SfB
"""

from datasets import load_dataset

dataset_val = load_dataset("google/boolq",split="validation")

# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilbert/distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilbert/distilgpt2")

import torch
import torch.nn.functional as F
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

def get_zero_shot_prediction(passage, question):
    # Construct prompt
    prompt = f"{passage}.\n{question}?\n"

    # Tokenize with truncation
    inputs = tokenizer(
        prompt,
        return_tensors="pt",
        truncation=True,
        max_length=1024,
    ).to(model.device)

    with torch.no_grad():
        outputs = model(**inputs)

    # Get the logits for the next token after the input
    next_token_logits = outputs.logits[0, -1, :]

    # Token IDs for "yes" and "no"
    yes_token = tokenizer.encode("yes", add_special_tokens=False)[0]
    no_token = tokenizer.encode("no", add_special_tokens=False)[0]

    # Get probabilities using softmax
    probs = F.softmax(next_token_logits[[yes_token, no_token]], dim=0)
    yes_prob, no_prob = probs.tolist()

    # Prediction
    predicted_answer = "yes" if yes_prob > no_prob else "no"
    return predicted_answer, yes_prob, no_prob

sample = dataset_val[0]
passage = sample["passage"]
question = sample["question"]
label = sample["answer"]  # True for "yes", False for "no"

pred, y_prob, n_prob = get_zero_shot_prediction(passage, question)

print(f"Q: {question}")
print(f"A: {pred} (yes_prob: {y_prob:.3f}, no_prob: {n_prob:.3f})")
print(f"Ground Truth: {'yes' if label else 'no'}")
print(f"Correct? {pred == ('yes' if label else 'no')}")

from sklearn.metrics import classification_report, accuracy_score
from tqdm import tqdm

true_labels = []
pred_labels = []

for sample in tqdm(dataset_val):  # use tqdm for progress bar
    passage = sample["passage"]
    question = sample["question"]
    label = "yes" if sample["answer"] else "no"

    pred, _, _ = get_zero_shot_prediction(passage, question)

    true_labels.append(label)
    pred_labels.append(pred)

# Print full classification report
print(classification_report(true_labels, pred_labels, digits=3))

# Also print accuracy
acc = accuracy_score(true_labels, pred_labels)
print(f"Overall Accuracy: {acc:.3f}")



with open("a3_p1_Shah_116727594.txt", "w") as file:
    file.write("CHECKPOINT 1.1\n")
    file.write(classification_report(true_labels, pred_labels, digits=3))
    file.write("\n")
    file.write(f"Overall Accuracy: {acc:.3f}\n")

# CHECKPOINT 1.2

dataset_train = load_dataset("google/boolq", split="train")

# Format each example as: "passage \n question? \n answer"
def format_example(example):
    prompt = f"{example['passage']}.\n{example['question']}?\n{'yes' if example['answer'] else 'no'}"
    return {"text": prompt}

formatted_dataset_train = dataset_train.map(format_example)
formatted_dataset_val = dataset_val.map(format_example)

tokenizer.pad_token = tokenizer.eos_token
model.config.pad_token_id = tokenizer.pad_token_id
def tokenize(example):
    return tokenizer(example["text"], truncation=True, padding="max_length", max_length=256)

tokenized_dataset_train = formatted_dataset_train.map(tokenize, batched=True)
tokenized_dataset_val = formatted_dataset_val.map(tokenize, batched=True)

def add_labels(example):
    example["labels"] = example["input_ids"]
    return example

tokenized_dataset_train = tokenized_dataset_train.map(add_labels)
tokenized_dataset_val = tokenized_dataset_val.map(add_labels)

tokenized_dataset_train.set_format(type='torch', columns=['question', 'answer', 'passage', 'text','input_ids', 'attention_mask', 'labels'])
tokenized_dataset_val.set_format(type='torch', columns=['question', 'answer', 'passage', 'text','input_ids', 'attention_mask', 'labels'])

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./finetuned-distilgpt2-boolq",
    per_device_train_batch_size=8,               # Increased batch size (T4 can handle this with fp16)
    num_train_epochs=1,                          # Reduced epochs to avoid overfitting on imbalance
    learning_rate=1e-5,                          # Safer LR for GPT-style models
    weight_decay=1e-2,                           # Regularization to help generalize
    fp16=True,                                   # Use fp16 for faster training on T4
    eval_strategy="epoch",                 # Evaluate each epoch
    save_strategy="epoch",                       # Save best model at each epoch
    load_best_model_at_end=True,                 # Ensures best checkpoint is kept
    logging_dir="./logs",
    logging_steps=20,
    metric_for_best_model="loss",
    greater_is_better=False,
    report_to="none"
)

from transformers import TrainerCallback,EarlyStoppingCallback,Trainer

class LossLoggerCallback(TrainerCallback):
    def __init__(self):
        self.train_logs = []

    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs and "loss" in logs:
            self.train_logs.append(logs["loss"])

loss_logger = LossLoggerCallback()

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset_train,
    eval_dataset=tokenized_dataset_val,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2), loss_logger]
)

trainer.train()

# Access the logs after training
train_logs = loss_logger.train_logs

import matplotlib.pyplot as plt

plt.plot(train_logs)
plt.xlabel("Logging Step")
plt.ylabel("Training Loss")
plt.title("Fine-tuning Loss Curve")
plt.grid(True)
plt.savefig("loss_curve.png")
plt.show()

trainer.save_model("./finetuned-distilgpt2-boolq")
tokenizer.save_pretrained("./finetuned-distilgpt2-boolq")

#CHECKPOINT 1.3

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from tqdm import tqdm

model.eval()
model.to(device)

true_labels = []
pred_labels = []

for sample in tqdm(tokenized_dataset_val):
    passage = sample["passage"]
    question = sample["question"]
    label = "yes" if sample["answer"] else "no"

    pred_label, _, _ = get_zero_shot_prediction(passage, question)

    pred_labels.append(pred_label)
    true_labels.append(label)

# Print classification results
print("\n" + classification_report(true_labels, pred_labels, digits=3, target_names=["no", "yes"]))
print(f"Overall Accuracy: {accuracy_score(true_labels, pred_labels):.3f}")
print("Confusion Matrix:")
print(confusion_matrix(true_labels, pred_labels, labels=["yes", "no"]))

report_text = classification_report(true_labels, pred_labels, digits=3, target_names=["no", "yes"])
acc = accuracy_score(true_labels, pred_labels)
conf_matrix = confusion_matrix(true_labels, pred_labels, labels=["yes", "no"])


with open("a3_p1_Shah_116727594.txt", "a") as file:
    file.write("CHECKPOINT 1.3\n\n")
    file.write("Classification Report:\n")
    file.write(report_text + "\n")
    file.write(f"Overall Accuracy: {acc:.3f}\n\n")
    file.write("Confusion Matrix (labels=['yes', 'no']):\n")
    for row in conf_matrix:
        file.write(" ".join(map(str, row)) + "\n")

#CHECKPOINT 1.4

from transformers import AutoModel, AutoTokenizer
import torch.nn as nn
import torch

class DistilRobertaForBinaryClassification(nn.Module):
    def __init__(self, model_name="distilbert/distilroberta-base"):
        super().__init__()
        self.roberta = AutoModel.from_pretrained(model_name)
        self.classifier = nn.Linear(self.roberta.config.hidden_size, 1)

    def forward(self, input_ids, attention_mask=None, labels=None):
        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)
        logits = self.classifier(outputs.last_hidden_state[:, 0, :]).squeeze(-1)
        loss = None
        if labels is not None:
            loss_fn = nn.BCEWithLogitsLoss()
            loss = loss_fn(logits, labels.float())
        return {"loss": loss, "logits": logits}

from datasets import load_dataset
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert/distilroberta-base")
dataset = load_dataset("boolq")

def preprocess(example):
    input_text = example["passage"] + ".\n" + example["question"] +"?\n"
    encoding = tokenizer(
        input_text, padding="max_length", truncation=True, max_length=256
    )
    encoding["label"] = int(example["answer"])
    return encoding

encoded_dataset = dataset.map(preprocess)
encoded_dataset = encoded_dataset.remove_columns(["question", "passage", "answer"])
encoded_dataset.set_format("torch")

from sklearn.metrics import f1_score, precision_score, recall_score
def compute_metrics(pred):
    logits, labels = pred
    preds = torch.sigmoid(torch.tensor(logits)) > 0.5
    preds = preds.int().numpy()

    # labels are already numpy arrays
    return {
        "accuracy": accuracy_score(labels, preds),
        "f1": f1_score(labels, preds),
        "yes_precision": precision_score(labels, preds, pos_label=1),
        "yes_recall": recall_score(labels, preds, pos_label=1),
        "yes_f1": f1_score(labels, preds, pos_label=1),
        "no_precision": precision_score(labels, preds, pos_label=0),
        "no_recall": recall_score(labels, preds, pos_label=0),
        "no_f1": f1_score(labels, preds, pos_label=0),
    }

from transformers import TrainerCallback

class LossPlotCallback(TrainerCallback):
    def __init__(self):
        self.losses = []

    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs and "loss" in logs:
            self.losses.append(logs["loss"])

loss_tracker = LossPlotCallback()

bce_training_args = TrainingArguments(
    output_dir="./results-boolq-distilroberta",
    per_device_train_batch_size=8,
    num_train_epochs=1,
    learning_rate=1e-5,
    weight_decay=1e-2,
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    logging_dir="./logs",
    logging_steps=20,
    metric_for_best_model="loss",
    greater_is_better=False,
    report_to="none",
    fp16=True
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_roberta = DistilRobertaForBinaryClassification().to(device)

trainer = Trainer(
    model=model_roberta,
    args=bce_training_args,
    train_dataset=encoded_dataset["train"],
    eval_dataset=encoded_dataset["validation"],
    compute_metrics=compute_metrics,
    callbacks=[loss_tracker]
)

trainer.train()
eval_results = trainer.evaluate()

print(f"""
Overall: acc: {eval_results['eval_accuracy']:.3f}, f1: {eval_results['eval_f1']:.3f}

    Yes: prec: {eval_results['eval_yes_precision']:.3f}, rec: {eval_results['eval_yes_recall']:.3f}, f1: {eval_results['eval_yes_f1']:.3f}

     No: prec: {eval_results['eval_no_precision']:.3f}, rec: {eval_results['eval_no_recall']:.3f}, f1: {eval_results['eval_no_f1']:.3f}
""")

# Append results to text file
with open("a3_p1_Shah_116727594.txt", "a") as file:
    file.write(f"""
Overall: acc: {eval_results['eval_accuracy']:.3f}, f1: {eval_results['eval_f1']:.3f}

    Yes: prec: {eval_results['eval_yes_precision']:.3f}, rec: {eval_results['eval_yes_recall']:.3f}, f1: {eval_results['eval_yes_f1']:.3f}

     No: prec: {eval_results['eval_no_precision']:.3f}, rec: {eval_results['eval_no_recall']:.3f}, f1: {eval_results['eval_no_f1']:.3f}
""")

import matplotlib.pyplot as plt

# Plot training loss
plt.figure(figsize=(10, 5))
plt.plot(loss_tracker.losses, label="Training Loss")
plt.xlabel("Logging Step")
plt.ylabel("Loss")
plt.title("Training Loss Curve")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("loss_curve2.png")
plt.show()